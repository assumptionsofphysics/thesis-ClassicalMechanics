\documentclass{article}
\usepackage{assumptionsofphysics}
\begin{document}

\title{Derivation Steps}

\section{Introduction}

	The purpose of this work is to re-derive Hamiltonian and Lagrangian mechanics. Historically the basis for the laws of physics were generalized experiences. These laws were rooted in the physical world rather than a mathematical one. As they are treated now, Hamiltonian and Lagrangian mechanics lack this physicality. They are taught as mathematical reformulations of Newtonian Mechanics which they are not. This work will begin with basic physical assumptions about a system in order to show it obeys Hamiltonian and Lagrangian Mechanics with a more physical justification. We will start with physical assumptions, then translate those assumptions into precise mathematical definitions. This will lead us to our results.

\section{Infinitesimal Reducibility}
	
\begin{assump}[Infinitesimal reducibility]
	The state of the system is reducible to the state of its infinitesimal parts. That is, giving the state of the whole system is equivalent to giving the state of its parts, which in turn is equivalent to giving the state of its subparts and so on.
\end{assump}

	We begin with the physical condition that differentiates classical and quantum mechanics: Reducibility. In classical mechanics we consider systems which are infinitesimally reducible. This means that we can identify the state the system is in by giving the state all of its components, then the states of the components of the components and so on. Now we must note we are not discussing point particles here. Our classical particles are in fact small regions of the large system which can still be broken up into further smaller regions. (continue this explanation).
	
	Explain in practical term what reducibility is. Give examples and counterexamples. Ball and red marker. Electron and photon scattering.
	
\subsection{Constraint on Coordinate Transformations}

Describe what the process of subdivision is, and define the particle as the limit of that process.

\begin{defn}
	The state space of the whole system is $\mathcal{C}$. A particle is an infinitesimal subdivision. The state space of the particles is $\mathcal{S}$. Each state of the whole is a distribution over the states of the parts.
\end{defn}

	%It is critical here to understand that the parts of the system that we consider are not point particles. They are simply small divisions of the composite system that we could continue to divide if we so chose.

So now we want to identify our state in S with numbers so that all states are uniquely labeled. This means for each degree of freedom of our state space we need a numerical value, so we write a map from our state space to n-dimensional Euclidean space. 

\begin{defn}
	A state variable assigns one numerical quantity to each state. Formally, it is a map $\xi : \mathcal{S} \to \mathbb{R}$. A complete set of state variables fully identifies a state. Formally, it is an invertible  map $\xi^\alpha : S \rightarrow \mathbb{R}^n $.
\end{defn}

Show how a composite system is a distribution over the parts. Discrete example: we have a box with balls of different colors. Suppose the state of the whole system will be defined by the number of balls for each color. $\mathcal{S}$ is the set of possible colors. $\rho(s)$ is the number of balls for each color. For each set of colors, we can count the balls that match that set. That is, for each $U \subset \mathcal{S}$ we have $\mu(U) = \sum_{s \in U} \rho(s)$. The whole state $c$ is determined by the function $\rho : \mathcal{S} \to \mathbb{R}$.

If it's continuous, we have two things. $\rho : \mathcal{S} \to \mathbb{R}$ is going to be a density. $\mu(U) = \int_{U} \rho(s) d\mathcal{S}$.

NOTE TO US: we are being subtle, and pretending that is just any integral, even though the fact that $\rho$ depends on the point constrains the problem.

\begin{defn}
	For each state of the composite system $c \in \mathcal{C}$ there is a unique distribution of the parts of the system over their state space. This distribution is written as $\rho_c: \mathcal{S} \rightarrow \mathbb{R}$ and describes the density of particles in the state at a point $s \in \mathcal{S}$. TODO $\mu$
\end{defn}

Discussion on units. Note that densities, in general, are coordinate dependent. Mass densities over three dimensional space $\mathcal{M}$. We can talk about points in a coordinate independent way. Point $A \in \mathcal{M}$, it's the same point in all references, and we do not need to even have a coordinate system defined to talk about point $A$. Now, if I have a mass distribution, and I ask you how much mass is there in a region $U \subseteq \mathcal{M}$, this is also coordinate independent . If I ask for the mass density at a point, however, I need to specify a quantity like $Kg/m^3$. Now I have to specify a "coordinate/unit" system of the space. In math terms, $\rho_m : \mathbb{R}^3 \to \mathbb{R}$ not $\rho_m : \mathcal{M} \to \mathbb{R}$.

Conceptually: $\rho$ changes as a scalar because it must be function of the state only (e.g. like temperature). But $\rho$ also changes as a density because the number of particles in a particular region of state space is independent of the "coordinates/units" used to identify the states.

\begin{prop}
	 and will transform as a scalar under a change of state variables A change of state variables must be differentiable and must have a unitary Jacobian i.e. $\left|\frac{\partial\hat{\xi}^b}{\partial\xi^a}\right| = 1$.
\end{prop}

TODO: Clarify all notion (including index notation). $a, b, b$ for state variables $i, j, k$ for unit variables. $\alpha, \beta, \gamma$ for unit+time. Where?

Distribution: $\rho$; state variables: $\xi^a$, state: $s$.

Distribution $\rho(s)$ as $\mathcal{S} \to \mathbb{R}$.  Density $\rho(\xi^a)$ as $\mathbb{R}^n \to \mathbb{R}$.  Density $\rho(\hat{\xi}^b)$ as $\mathbb{R}^n \to \mathbb{R}$. Variables values: $\xi^a(s)$ as $\mathcal{S} \to \mathbb{R}^n$. Point from values: $s(\xi^a)$ as $\mathbb{R}^n \to \mathcal{S}$

Following identity $\rho(s(\xi^a)) = \rho(\xi^a)$. $\rho(s) = \rho(s (\xi^a(s)))$

\subsection{Unit Variables, Conjugate Pairs, and 2n Dimensional State Space}

Talk about unit system in general: some choices are free, some are dependent. Give example of dependent/independent unit variables (like velocity down)

If we change one of these unit variables, we will also have to change any other state variables that depend on the definition of the unit we changed. For example if $q^1$ defines the position relative to the x-axis in meters and $k_1$ is the velocity relative to the x-axis in meters per second, a change in $q^1$ to kilometers would necessitate a change in $k_1$ to kilometers per second. So a change of units $\hat{q}^j = \hat{q}^j(q^i)$ will induce a unique change of state variables $\hat{\xi}^b = \hat{\xi}^b(\xi^a)$.

\begin{defn}
	We define a unit variable $q \in \xi^a$ as a state variable that is the definition of a unit. The set of unit variables $q^i \in \xi^a$ defines a unit system upon which the other state variables depend.
\end{defn}



\begin{prop}
	The state space of the particles is $2n$ dimensional. The state variables are organized in pairs $\{q^i, k_i\}$ with a well defined transformation rule.
\end{prop}

\subsection{Areas in State Space and Poisson Brackets}
	
\begin{prop}
	For each independent degree of freedom, the area given $\int_U \hbar dq^i dk_i = \int_U dq^i dp_i$ quantifies the number of possible configurations within the region $U$.
\end{prop}

 This is the classical equivalent of the quantum commutator.

\begin{defn}
	The Poisson bracket is defined as $\{f,g\} = \frac{\partial f}{\partial x}\frac{\partial g}{\partial p} - \frac{\partial g}{\partial x}\frac{\partial f}{\partial p}$.
\end{defn}

\begin{prop}
	The Poisson bracket $\{f, g\}$ translates the densities of states into densities per unit area of $f, g$. It is the Jacobian of the transformation $dfdg \rightarrow dxdp$ i.e. $dfdg = \{f,g\}dxdp$.
\end{prop}
	
\section{Reversible and Deterministic Evolution}

\begin{assump}[Reversible and Deterministic Evolution]
	The system undergoes Reversible and Deterministic Evolution meaning given the state of the system at any time, its state at all past and future times is known.
\end{assump}

Particle states change in time. But we have a law of how to go from one state to the other. Bijection $\mathcal{T}_{\Delta t} : \mathcal{S} \to \mathcal{S}$ ... This only gives you the infinitesimal displacement in time.

\begin{defn}
	We write $\lambda: \mathbb{R} \rightarrow \mathcal{S}$ defined as $s = \lambda(t)$ as the evolution of the state of one particle. Now the density associated with the state at $t_0$ is given by $\rho_c(\lambda(t_0),t_0)$.
\end{defn}

	%By our condition of Deterministic and Reversible evolution we must have $\rho(\lambda(t_0),t_0) = \rho(\lambda(t),t)$ meaning this density of states is conserved over time. So all particles that begin in the same state will evolve through and end in the same states. Now going back to our integral $\int_{\Sigma} \rho_c\omega(d\Sigma)$ we will find that our region $\Sigma$ is mapped to a new region in state space as the system evolves, but the same fraction of the parts of the system will be found in that region.
	
As particle states move, the will "drag" along the same evolution all the particles that are associated with that state. This is going to tell you that the infinitesimal displacement is "divergenceless" (conserves density)

\begin{prop}
	The density $\rho_c(s,t)$ in conserved. This means that while particles may change state over the course of the system's evolution, any particles that begin in the same state will be found in the same state throughout the evolution no matter what point in time is chosen. So we have $\rho(\lambda(t_0),t_0) = \rho(\lambda(t),t)$. (diagram showing conserved volumes/areas)
\end{prop}

\begin{prop}
	The above conditions are sufficient to say that our system is Hamiltonian and thus satisfies Hamilton's equations. So the evolution of the system can be written in the familiar way:
	$$d_tq^i = \partial_{p_i}H$$
	$$d_tp_i = -\partial_{q^i}H$$
\end{prop} 
	
	%The incredible thing here is that from two assumptions we can derive the entirety of Hamiltonian mechanics. 

\section{Kinematic Equivalence}

\begin{assump}[Kinematic Equivalence]
	(More physicsy) There is a invertible bijection between trajectories in phase space and trajectories in physical space-time. (diagram showing bijection)
\end{assump}

\subsection{Weak Equivalence}

\begin{defn}
	We take $x^i = q^i$. We then define $v_i = d_tx^i$. Weak equivalence means $v_i(q^i, p_i)$ is invertible.
\end{defn}

(photon counter-example $v^i$ function only of $x^i$)

\begin{prop}
	TO REMOVE. $x^i = q^i$ and $v^i = d_tx^i = v^i(q^j,p_k)$ hold at all times $t$.  This is called weak equivalence meaning $v^i$ is invertible at every $q^i$. 
\end{prop}

\begin{prop}
	A classical system that satisfies weak equivalence is Lagrangian system. Formally, ....
\end{prop}

\subsection{Full Equivalence}

The unit that I use to express the density on position and velocity must dependent only on $q^i$, if they are to fully define the unit system.

\begin{defn}
	Full equivalence means that Kinematic Equivalence extends to the composite system. So we have $\rho(q^i,p_j) = \left|J\right|\rho(x^i,v^j) = \left|\frac{\partial v^i}{\partial p_j}\right|\rho(x^i,v^j)$. The Jacobian is only a function of $q^i$.
\end{defn}

\begin{prop}
	A system that satisfies full kinematic equivalence obeys the laws of massive particles under potential forces.
\end{prop}
	

\subsection{Action Principle}

I think it would be nice to show how the Action Principle is simply a consequence of our assumptions just so readers have a reference to something they are already familiar with.

\section{Overall Picture of Classical Mechanics, Connections with other Areas} 

\subsection{The Three Formulations of Classical Mechanics}

\subsection{Connections with Quantum}

\subsection{Connections with Statistical Mechanics}


\section{Conclusion}
	
















\end{document}
